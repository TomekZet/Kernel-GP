\documentclass{article}
\usepackage{polski} %może wymagac dokonfigurowania latexa, ale jest lepszy niż standardowy babel'owy [polish]
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[OT4]{fontenc}
\usepackage{amsfonts}
\usepackage{graphicx,color} %include pdf's (and png's for raster graphics... avoid raster graphics!)
\usepackage{url}
\usepackage[pdftex,hyperfootnotes=false,pdfborder={0 0 0}]{hyperref} %za wszystkimi pakietami; pdfborder nie wszedzie tak samo zaimplementowane bo specyfikacja nieprecyzyjna; pod miktex'em po prostu nie widac wtedy ramek
\usepackage[section]{placeins}

\input{_ustawienia.tex}

\begin{document}

\input{_tytulowa}


\begin{abstract}
\emph{SVM} 
\end{abstract}


\section{Wstęp}
	\subsection{Opis eksperymentu}
	Celem eksperymentu było użycie programowania genetycznego do wyewoluowania optymalnych funkcji jądrowych dla klasyfikatora \emph{SVM}.
	Klasyfikator SVM dokonuje klasyfikacji binarnej oddzielając od siebie dwie grupy przykładów hiperpłaszczyzną przebiegającą w przestrzeni atrybutów opisujących przykłady. Najczęściej grupy te nie są liniowo separowalne i trzeba dokonać transformacji cech opisujących przykłady do przestrzeni o większej liczbie wymiarów tak, żeby były w niej liniowo separowalne. Funkcje używane do dokonania tej transformacji to funkcje jądrowe  (inczej kernele  - ang. kernel functions). Wybór odpowiedniej funkcji zależy od rozwiązywanego problemu i zazwyczaj opiera się na doświadczeniu osoby używającej klasyfikator, posiadanej przez nią wiedzy dziedzinowej. W przypadku nie znanych apriori danych wejściowych i braku doświadczenia w wyborze optymalnej funkcji jądrowej można posłużyć się automatycznymi metodami optymalizacji. Wśród nich idalną do tego zadania wydaje się \definicja{programowanie geetyczne} (\akronim{GP} - \english{Genetic Programming}). Jest to szczególny rodzaj \definicja{obliczeń ewolucyjnych} (\akronim{EC} - \english{Evolutionary Computing}), w którym ewoluowane osobniki to funkcje reprezentowane za pomocą struktur drzewiastych.
	Na potrzeby eksperymentu zaprojektowano algorytm programowania genetycznego, który ewoluował funkcje jądrowe poprzez łączenie ze sobą prostych funkcji jądrowych w funkcje złożone za pomocą funkcji łączących.

\subsection{Opis algorytmu}
	Przebieg algorytmu jest typowy dla algorytmów genetycznych:
\begin{enumerate}
\item Utwórz początkową populację kerneli
\item \label{ewaluacja} Oblicz wartość \textit{funkcji dopasowania} każdego z kerneli: dokładność klasyfikacji SVM z użyciem tego kernela
\item Jeśli znaleziono idealny kernel (dokładność klasyfikacji 100 ) lub skończył się czas, użyj tego kernela do klasyfikacji zbioru walidującego, zwróć wyniki klasyfikacji i zakończ algorytm.
\item Dokonaj selekcji najlepszych funkcji z populacji
\item Utwórz nową populację poprzez mutację i krzyżowanie wybranych w poprzednim kroku funkcji
\item Wróć do punktu \ref{ewaluacja}
\end{enumerate}

\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/algorithm}
\caption{Diagram przepływu algorytmu Kernel GP.\label{fig:algorithm}}
\end{figure}

Algorytm pokazano również na diagramie przepływu na rycinie \ref{fig:algorithm}. 
Poszczególne kroki algorytmu zostaną opisane poniżej.

\subsection{Inicjalizacja populacji}
Podczas inicjalizacji początkowo pusta populacja jest zapełniana przez generowane w sposób losowy drzewa reprezentujące funkcje. Generowane drzewa muszą być poprawne, czyli spełniać narzucone ograniczenia na głębokość drzewa, liczbę węzłów, typ wartości zwracanych przez drzewo.
Wielkość populacji jest jednym z parametrów algorytmu. Zbyt mała populacja powoduje losowe zawężenie przeszukiwanej przestrzeni i zmniejsza prawdopodobieństwo znalezienia optymalnej funkcji. Z drugiej strony zbyt duża wielkość populacji upodabnia algorytm genetyczny do pełnego przeszukiwania, co oczywiście zwiększa szanse znalezienia optymalnego kernela, ale wydłuża czas działania algorytmu.

\subsubsection{Generowanie funkcji}
Generowanie drzew reprezentujących funkcje jądrowe polega na łączeniu ze sobą funkcji elementarnych zgodnie z  przypisanymi im ograniczeniami.
Funkcje elementarne wraz z ograniczeniami zdefiniowane w algorytmie:
\begin{itemize}
\item Funkcje łączące - jako argument przyjmują wynik dwóch lub jednej funkcji jądrowej i ewentualnie stałą \emph{ERC}. Zwracają wartość rzeczywistą. Dzięki właściwości domknięcia zbioru kerneli ze względu na operacje wykonywane przez te funkcje funkcja powstała przez połączenie dwóch kerneli funkcją łączącą jest również poprawnym kernelem \cite{Shawe-Taylor:2004:KMP:975545}.
	\begin{itemize}
	\item Dodawanie: $ k(x, z) = k_1(x,z) + k_2(x,z) $
	\item Mnożenie: $ k(x, z) = k_1(x,z) * k_2(x,z) $	
	\item Mnożenie przez stałą: $ k(x, z) = a * k_1(x,z) $
	\item Funkcja wykładnicza: $ k(x, z) = e ^{k_1(x,z)} $
	\end{itemize}
	Gdzie $ a $ to stała rzeczywista generowana jako stała \emph{ERC}.
\item Podstawowe funkcje jądrowe - jako argument przyjmują odpowiednią do funkcji liczbę stałych ERC. Zwracają wartość rzeczywistą.
	\begin{itemize}
	\item Liniowa: $ k(x, z) = \langle x,z \rangle $	
	\item Wielomianowa: $ k(x, z) = \langle x,z \rangle ^d $
	\item Gausowska: $ e^{-\gamma*||x-z||^2} $	
	\item Sigmoidalna: $ k(x, z) = \tanh(\gamma \langle x,z \rangle + \tau) $
	\end{itemize}
	Gdzie $ \gamma $, $ \tau $ oraz $ d $ to wartości stałe generowane jako stałe \emph{ERC}. a $ \langle x,y \rangle $ to iloczyn skalarny wektorów $x$ i $y$.
\item Stałe \akronim{ERC} (\english{Ephemeral Random Constant}) liczby rzeczywiste lub całkowite, które służą jako parametry innych funkcji. Są one liściami w drzewie, nie przyjmują żadnych argumentów. Mogą losowo zmieniać swoją wartość podczas mutacji.
	\begin{itemize}
	\item $ \gamma $: liczba rzeczywista z zakresu
	\item $ \tau $: liczba rzeczywista z zakresu
	\item $ d $: liczba całkowita z zakresu
	\item $ a $: liczba rzeczywista z zakresu
	\end{itemize}
\end{itemize}
Przykładowe drzewo wygenerowane przez algorytm pokazana na ryc.\ref{fig:tree}.

Wektory cech będące najważniejszymi argumentami funkcji jądrowych nie są wyodrębnione jako osobne węzły budujące drzewo, ponieważ są one danymi wejściowymi ewoluowanych funkcji i dla każdej ewoluowanej funkcji są takie same.		

\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/tree}
\caption{Przykładowe drzewo generowane przez algorytm.\label{fig:tree}}
\end{figure}


\subsection{Ewaluacja kerneli}
Ewaluacja funkcji jądrowej może odbywać się na jeden z dwóch sposobów. Jeśli w zbiorze danych oprócz zbioru uczącego wydzielono zbiory testowy i walidujący, to sprawdzany kernel jest używany do klasyfikacji danych ze zbioru testującego. Trafność klasyfikacji zostaje przeliczona na wartość \textit{ funkcji przystosowania} ewaluowanej funkcji jądrowej.
Jeśli w zbiorze danych wydzielono tylko dwa podzbiory: uczący i walidujący, to zdolność klasyfikacji przez kernel jest oceniana za pomocą \textit{walidacji krzyżowej (ang. cross-validation}.
Walidacja krzyżowa pozwala użyć więcej danych podczas fazy uczenia, jednak wiąże się ze znacznym wzrostem złożoności obliczeniowej - zamiast jednej klasyfikacji musimy przeprowadzić k procesów uczenia i k klasyfikacji.

\subsection{Selekcja}
Jednym z problemów programowania genetycznego jest to, że drzewa powstałe w wyniku procesu ewolucyjnego mogą być bardzo duże, co nie jest pożądaną cechą - większe drzewo dłużej oblicza zwracaną wartość, zajmuje więcej miejsc w pamięci. Dlatego wielkość drzew należy ograniczać, jeśli wzrost drzewa nie prowadzi do zwiększenia wartości funkcji dopasowania.
Wielkość generowanych drzew jest regulowana przez dwa mechanizmy. Pierwszy to proste ograniczenie na maksymalną głębokość drzewa. Wartość tę ustawiono na 6 - drzewa o większej głebokości nie zostaną w ogóle wygenerowane przez podczas inicajlizacji populacji czy podczas krzyżowania i mutacji. Drugi mechanizm, o angielskiej nazwie \textit{parsimony pressure},  promuje mniejsze drzewa podczas selekcji. W tym celu stosowany jest algorytm selekcji turniejowej leksykograficznej z koszykami (ang. Bucket Lexicographic
 Tournament Selection). Algorytm ten sortuje populację według przystosowania osobników, następnie grupuje je w N "koszyki". Następnie selekcja przebiega według zasad selekcji turniejowej, z tym, że porównuje się nie przystosowanie osobników, ale koszyk, do którego są przypisane. W przypadku gdy w turnieju porównywane są dwa osobniki z tego samego koszyka wygrywa ten, który jest mniejszy.

\subsection{Krzyżowanie i mutacja}
Krzyżowanie polega na odcięciu dwóch losowych poddrzew z dwóch różnych osobników i zamianie ich miejscami. Wygenerowane w ten sposób drzewo musi spełniać narzucone na drzewo ograniczenia dotyczące typów i wielkości.
Mutacja drzew polega na zamianie losowo wybranego poddrzewa przez losowo wygenerowane drzewo.
Dodatkowo mutowane są również węzły ERC. Ich mutacja polega na dodaniu losowej wartości o rozkładzie normalnym do wartości przechowywanej w węźle. Wartość ta może być ujemna lub dodatnia.
Mutacji podlega $ 90\% $ drzew, pozostałe $ 10\% $ jest pozostawiane bez zmian. Wszystkie drzewa podlegające mutacji mają mutowane węzły ERC. Ponadto $ 70\% $ z nich podlega krzyżowaniu, $ 20\% $ mutacji polegającej na generowaniu losowych poddrzew a $ 10\% $ ma mutowane jedynie węzły ERC.

\subsection{Walidacja rozwiązania}
Walidacja polega na użyciu najlepszego znalezionego Kernela do klasyfikacji przykładów ze zbioru walidującego, który nie był używany podczas uczenia klasyfikatora SVM ani podczas ewaluacji kerneli. Otrzymana w wyniku tej klasyfikacji trafność jest miarą oceny całego algorytmu Kernel GP.

\section{Implementacja}
Algorytm został napisany w języku Java z użyciem bibliotek \textit{ECJ (Evolutionary Computing in Java)} \cite{sean_ecj_2010} oraz LibSVM \cite{chang_libsvm:_2011}. Pierwsza z nich dostarcza mechanizmy \textit{obliczeń ewolucyjnych} w tym \textit{programowania genetycznego}.
\emph{LibSVM} to klasyfikator SVM napisany oryginalnie w języku C z dostępną implementacją w Javie.
Mechanizmy \emph{ECJ} stanowią trzon algorytmu zapewniając tworzenie populacji funkcji, ich selekcję, mutację oraz krzyżowanie. \emph{LibSVM} został użyty na etapie ewaluacji wygenerowanych przez \emph{ECJ} funkcji.
	
	
	
	

%			\begin{figure}[ht]
%				\includegraphics[scale=0.90]{../results/quality}
%				\caption{Porównanie średniej jakości rozwiązań generowanych przez algorytmy dla różnych instancji \emph{QAP}\label{fig:quality}}
%			\end{figure}

\section{Wyniki}
	\subsection{Zbiory danych}
	Do oceny pracy algorytmu użyto standardowych zbiorów danych służących do testowania systemów maszynowego uczenia się, dostępnych na stronie biblioteki \emph{LIBSVM}. Zbiory zostały opisane w tabelce \ref{tab:datasets}.



\begin{table}[ht]
\begin{tabular}{||p{2cm}|c|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}||}
	\hline 
	Nazwa zbioru & Liczba klas & \hspace{0pt} Liczba atrybutów & \hspace{0pt} Wielkość zbioru uczącego & \hspace{0pt}Wielkość zbioru testującego & \hspace{0pt} Wielkość zbioru walidującego \\
	\hline 
	Iris & 3 & 4 & 68 & 33 & 49  \\ 
	\hline 
	Letter & 26 & 16 & 9000 & 4400 & 6600\\ 
	\hline 
	DNA & 3 & 180 & 1435 & 700 & 1051 \\ 
	\hline 
	Vowel & 11 & 10 & 447 & 217 & 326 \\ 
	\hline
	\end{tabular} 	
	\caption{Zbiory danych użyte do testowania systemu.\label{tab:datasets}} 	
\end{table}
	
	\subsection{Metodologia pomiarów}
	Żeby oszacować trafność klasyfikacji osiąganą przez skonstruowany system konieczne było podzielenie zbioru danych na zbiór uczący i walidujący, a w przypadku algorytmu Kernel-GP również wydzielenie ze zbioru uczącego podzbioru testującego, używanego do obliczania miary przystosowania (fitness) podczas przebiegu algorytmu genetycznego. Ponieważ sposób podziału zbioru danych ma wpływ na osiąganą trafność klasyfikacji, dokonywano, w zależności od zbioru, 5 lub 10 takich podziałów a następnie wyciągano średnią oraz odchylenie standardowe z wyników otrzymanych dla tych podziałów. Ta procedura dotyczyła zarówno testowania algorytmu \emph{Kernel-GP} jak i porównawczych testów klasyfikatora SVM z biblioteki \emph{LibSVM}. Dla obu algorytmów stosowano te same podziały danych, przy czym w przypadku klasyfikatora \emph{LibSVM} nie dzielono zbioru uczącego na trenujący i testujący.
	

	\subsection{Trafność klasyfikacji}
	Jak widać na rysunkach \ref{fig:acc-iris} - \ref{fig:acc-letter-detailed} sprawność algorytmu zależy mocno od konkretnego zbioru danych.
	\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-iris}
		\caption{Dokładność klasyfikacji dla zbioru \emph{iris} w funkcji rozmiaru populacji dla róznych ilości generacji.\label{fig:acc-iris}}
	\end{figure}
	
	\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-iris-detailed}
		\caption{Dokładność klasyfikacji dla zbioru \emph{iris} w funkcji rozmiaru populacji dla róznych ilości generacji, dla małych populacji.	\label{fig:acc-iris-detailed}}
	\end{figure}	
	
	
		\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-dna}
		\caption{Dokładność klasyfikacji dla zbioru \emph{DNA} w funkcji rozmiaru populacji dla róznych ilości generacji.\label{fig:acc-dna}}
	\end{figure}
	
		\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-dna-detailed-sd}
		\caption{Dokładność klasyfikacji dla zbioru \emph{DNA} w funkcji rozmiaru populacji dla róznych ilości generacji, dla małych populacji.\label{fig:acc-dna-detailed}}
	\end{figure}	
	

		\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-vowel}
		\caption{Dokładność klasyfikacji dla zbioru \emph{vowel} w funkcji rozmiaru populacji dla róznych ilości generacji.\label{fig:acc-vowel}}
	\end{figure}
		
				\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-vowel-detailed}
		\caption{Dokładność klasyfikacji dla zbioru \emph{vowel} w funkcji rozmiaru populacji dla róznych ilości generacji, dla małych populacji.\label{fig:acc-vowel-detailed}}
	\end{figure}
	
	
		\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-letter}
		\caption{Dokładność klasyfikacji dla zbioru \emph{letter} w funkcji rozmiaru populacji dla róznych ilości generacji.\label{fig:acc-letter}}
	\end{figure}
		
				\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-letter-detailed}
		\caption{Dokładność klasyfikacji dla zbioru \emph{letter} w funkcji rozmiaru populacji dla róznych ilości generacji, dla małych populacji.\label{fig:acc-letter-detailed}}
	\end{figure}
		


	\subsection{Porównanie z tradycyjnym algorytmem SVM}
	\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-iris-svm}
		\caption{Porównanie dokładności klasyfikacji dla zbioru \emph{iris} przez algorytm SVM z różnymi funkcjami jądrowymi i algorytm Kernel-GP\label{fig:acc-iris-svm}}
	\end{figure}
	
		\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-dna-svm}
		\caption{Porównanie dokładności klasyfikacji dla zbioru \emph{dna} przez algorytm SVM z różnymi funkcjami jądrowymi i algorytm Kernel-GP.\label{fig:acc-dna-svm}}
	\end{figure}	
	
		\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-vowel-svm}
		\caption{Porównanie dokładności klasyfikacji dla zbioru \emph{vowel} przez algorytm SVM z różnymi funkcjami jądrowymi i algorytm Kernel-GP\label{fig:acc-vowel-svm}}
	\end{figure}
	
		\begin{figure}[ht]
		\includegraphics[scale=0.90]{../ecj-svm/results/processed/pdf/accuracy-letter-svm}
		\caption{Porównanie dokładności klasyfikacji dla zbioru \emph{letter} przez algorytm SVM z różnymi funkcjami jądrowymi i algorytm Kernel-GP\label{fig:acc-letter-svm}}
	\end{figure}		
		
		
\section{Podsumowanie}
	\subsection{Wnioski}
		\begin{itemize}
			\item 
		\end{itemize}


%%%%%%%%%%%%%%%% literatura %%%%%%%%%%%%%%%%

\bibliography{bibliografia}
\bibliographystyle{plain}

\end{document}

